# Cerebras Getting Started

## On Boarding 

See [ALCF AI Testbed User Guide](https://www.alcf.anl.gov/support-center/get-started) to request an account and additional information.

## System View

![CS-2 connection diagram](./Cerebras-connectivity-diagram.png)
Connection to a CS-2 node is a two-step process. The first step requires a MFA passcode for authentication - either a 8 digit passcode generated by an app on your mobile device (e.g. mobilePASS+) or a CRYPTOCard-generated passcode prefixed by a 4 digit pin. 

In the examples below, replace `ALCFUserID` with your ALCF user id.

To connect to a CS-2 ("chief") node:<br>

1. From the local machine, ssh to the login node first: 
    ```bash
    ssh ALCFUserID@cerebras.alcf.anl.gov
    ```
<!-- 2. From the login node, ssh to the destination CS-2 chief node:
    ```bash
    ssh cs2-01-master
   # or
    ssh cs2-02-master
    ``` -->

# Steps to run BERT-Large on CS-2

<!-- 1. Login to CS-2 login node. 
    ```bash
      $ ssh ALCFUserID@cerebras.alcf.anl.gov 
    ``` -->

1. BERT Code is in the [Bert](./bert/) directory of this repository. For your convenience, this code is also available locally. 
   Copy BERT code to your `$HOME` directory. 
    ```bash
    $ cp -r /projects/aitestbed_training/CS-2/model_zoo ~/  
    $ cd bert  
    ```

2. Connect to the one of the destination CS-2 chief node:  
    ```bash
    $ ssh cs2-01-master 
    or 
    $ ssh cs2-02-master
    ```

3. The CS-2 systems use SLURM for job submission and queueing. Please refer to [Cerebras Documentation](https://www.alcf.anl.gov/support/ai-testbed-userdocs/cerebras/Job-Queuing-and-Submission/index.html) for further details. 
  
  
* **Run scripts on CS-2 with Pre-Compiled Model:**
To further reduce the execution time we have precompiled model. For your conveneice, the precompiled model is available at `/projects/aitestbed_training/CS-2/precompiled_bert`. Here are commands to run it. 

  * Copy precompiled model direcotry to your `$HOME` directory. 
    ```bash
    $ cp -r /projects/aitestbed_training/CS-2/precompiled_bert ~
    ```
  * `csrun_wse` is used to run a job on both the wafer scale engine and one or more worker nodes.
    ```bash
    $ MODELDIR=$HOME/precompiled_bert
    $ time -p csrun_wse python run.py --mode=train --params configs/params_bert_large_msl128_fast.yaml --model_dir $MODELDIR --cs_ip $CS_IP
    ```
   This will take approximately `#todo` minutes to run. Here is the sample output 

   <details>
   <summary>Click for Sample Output</summary>

   ```bash
   $ ToDo
   $ ToDo
   $ ToDo
   $ ToDo
   $ ToDo
   ```

   </details>
  
  * **Run scripts on CS-2:** 
  We will use  `params_bert_large_msl128_fast.yaml` config file that runs BERT for 100 steps to reduce executiuon time during the period of tutorial.  
  `csrun_wse` is used to run a job on both the wafer scale engine and one or more worker nodes.

    ```bash
    $ MODELDIR=model_dir_bert_large_msl128_$(hostname)  
    $ rm -r $MODELDIR 
    $ time -p csrun_wse python run.py --mode=train --params configs/params_bert_large_msl128_fast.yaml --model_dir $MODELDIR --cs_ip $CS_IP
    ```
    
    This will take approximately `#todo` minutes to run. Here is the sample output 

    <details>
    <summary>Click for Sample Output</summary>

    ```bash
    $ ToDo
    $ ToDo
    $ ToDo
    $ ToDo
    $ ToDo
    ```

    </details>

    * **Note** : 
    The original config file is `configs/params_bert_large_msl128.yaml` which should be used when the machine is not busy post tutorial. This will take approximately `#todo` minutes to run.

  <!-- * **Run scripts on CPU:**  
   `csrun_cpu` is used to run a cpu-only job on one or more worker nodes.

    ```bash
    $ MODELDIR=model_dir_bert_large_msl128_$(hostname)  
    $ rm -r $MODELDIR  
    $ time -p csrun_cpu python run.py --mode=train --compile_only --params configs/params_bert_large_msl128.yaml --model_dir $MODELDIR --cs_ip $CS_IP  
    ```
    This will take approximately `#todo` minutes to run. Here is the sample output 

    <details>
    <summary>Click for Sample Output</summary>

    ```bash
    $ ToDo
    $ ToDo
    $ ToDo
    $ ToDo
    $ ToDo
    ```

    </details> -->


## Other Models and Use-cases 

* See [Example Programs](https://www.alcf.anl.gov/support/ai-testbed-userdocs/cerebras/Example-Programs/index.html) for instructions to run other well-known AI applications on Cerebras hardware (e.g., UNet, BragNN etc)








